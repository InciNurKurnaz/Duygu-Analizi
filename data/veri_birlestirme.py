from pathlib import Path
import pandas as pd


# ===================== KLASÃ–R YAPISI =====================

DATA_DIR = Path(r"C:\DuyguAnalizi\data")  # Veri klasÃ¶rÃ¼nÃ¼zÃ¼n yolu

TWITTER_TRAIN = DATA_DIR / "train_tweets_set.csv"
TWITTER_TEST = DATA_DIR / "test_tweets_set.csv"
STORE_REVIEWS = DATA_DIR / "magaza_yorumlari_duygu_analizi.csv"  # Senin dosya adÄ±n

OUTPUT_TRAIN = DATA_DIR / "train_set.csv"
OUTPUT_TEST = DATA_DIR / "test_set.csv"


# ===================== VERÄ° OKUMA =====================

def read_twitter_csv(filepath):
    """Twitter verilerini oku (;) ile ayrÄ±lmÄ±ÅŸ"""
    data = []
    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.rsplit(';', 1)
            if len(parts) == 2:
                text, sentiment = parts[0].strip(), parts[1].strip().lower()
                if text and sentiment:
                    data.append([text, sentiment])
    return pd.DataFrame(data, columns=['text', 'sentiment'])


def read_store_csv(filepath):
    """MaÄŸaza yorumlarÄ±nÄ± oku (,) ile ayrÄ±lmÄ±ÅŸ"""
    data = []
    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            # VirgÃ¼l ile ayÄ±r ama son virgÃ¼l sentiment iÃ§in
            parts = line.rsplit(',', 1)
            if len(parts) == 2:
                text, sentiment = parts[0].strip(), parts[1].strip().lower()
                if text and sentiment:
                    data.append([text, sentiment])
    return pd.DataFrame(data, columns=['text', 'sentiment'])


# ===================== ETÄ°KET STANDARTLAÅTIRMA =====================

def standardize_labels(df):
    """TÃ¼m etiketleri standart formata Ã§evir"""
    label_map = {
        # Pozitif varyasyonlar
        'olumlu': 'pozitif', 'pozitif': 'pozitif', 'positive': 'pozitif',
        'iyi': 'pozitif', 'gÃ¼zel': 'pozitif', '5': 'pozitif', '4': 'pozitif',

        # Negatif varyasyonlar
        'olumsuz': 'negatif', 'negatif': 'negatif', 'negative': 'negatif',
        'kÃ¶tÃ¼': 'negatif', 'berbat': 'negatif', '1': 'negatif', '2': 'negatif',

        # NÃ¶tr varyasyonlar
        'tarafsÄ±z': 'notr', 'nÃ¶tr': 'notr', 'notr': 'notr', 'neutral': 'notr',
        'orta': 'notr', 'fena deÄŸil': 'notr', '3': 'notr'
    }

    df['sentiment'] = df['sentiment'].map(label_map)
    df.dropna(subset=['sentiment'], inplace=True)
    return df


# ===================== ANA FONKSÄ°YON =====================

def merge_datasets():
    """TÃ¼m veri setlerini birleÅŸtir"""

    print("=" * 70)
    print("VERÄ° SETLERÄ°NÄ° BÄ°RLEÅTÄ°RME")
    print("=" * 70)

    # 1. Twitter verilerini yÃ¼kle
    print("\nğŸ“‚ Twitter eÄŸitim seti yÃ¼kleniyor...")
    df_twitter_train = read_twitter_csv(TWITTER_TRAIN)
    print(f"âœ… {len(df_twitter_train)} satÄ±r yÃ¼klendi")

    print("\nğŸ“‚ Twitter test seti yÃ¼kleniyor...")
    df_twitter_test = read_twitter_csv(TWITTER_TEST)
    print(f"âœ… {len(df_twitter_test)} satÄ±r yÃ¼klendi")

    # 2. MaÄŸaza yorumlarÄ±nÄ± yÃ¼kle
    if STORE_REVIEWS.exists():
        print("\nğŸ“‚ MaÄŸaza yorumlarÄ± yÃ¼kleniyor...")
        df_store = read_store_csv(STORE_REVIEWS)
        print(f"âœ… {len(df_store)} satÄ±r yÃ¼klendi")
    else:
        print(f"\nâš ï¸ MaÄŸaza yorumlarÄ± bulunamadÄ±: {STORE_REVIEWS}")
        print("ğŸ’¡ Sadece Twitter verileri kullanÄ±lacak")
        df_store = pd.DataFrame(columns=['text', 'sentiment'])

    # 3. Etiketleri standartlaÅŸtÄ±r
    print("\nğŸ”§ Etiketler standartlaÅŸtÄ±rÄ±lÄ±yor...")
    df_twitter_train = standardize_labels(df_twitter_train)
    df_twitter_test = standardize_labels(df_twitter_test)
    if not df_store.empty:
        df_store = standardize_labels(df_store)

    # 4. MaÄŸaza verilerini %80-20 bÃ¶l
    if not df_store.empty:
        from sklearn.model_selection import train_test_split
        store_train, store_test = train_test_split(
            df_store, test_size=0.2, random_state=42,
            stratify=df_store['sentiment']
        )
        print(f"   MaÄŸaza â†’ EÄŸitim: {len(store_train)}, Test: {len(store_test)}")
    else:
        store_train = pd.DataFrame(columns=['text', 'sentiment'])
        store_test = pd.DataFrame(columns=['text', 'sentiment'])

    # 5. BirleÅŸtir
    combined_train = pd.concat([df_twitter_train, store_train], ignore_index=True)
    combined_test = pd.concat([df_twitter_test, store_test], ignore_index=True)

    # 6. Temizlik
    combined_train.drop_duplicates(subset=['text'], inplace=True)
    combined_test.drop_duplicates(subset=['text'], inplace=True)

    # 7. SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
    print("\nğŸ“Š BirleÅŸtirilmiÅŸ EÄŸitim Seti DaÄŸÄ±lÄ±mÄ±:")
    print(combined_train['sentiment'].value_counts())

    print("\nğŸ“Š BirleÅŸtirilmiÅŸ Test Seti DaÄŸÄ±lÄ±mÄ±:")
    print(combined_test['sentiment'].value_counts())

    # 8. Kaydet
    combined_train.to_csv(OUTPUT_TRAIN, sep=';', index=False, header=False)
    combined_test.to_csv(OUTPUT_TEST, sep=';', index=False, header=False)

    print(f"\nâœ… BirleÅŸtirilmiÅŸ eÄŸitim seti: {OUTPUT_TRAIN}")
    print(f"   Toplam: {len(combined_train)} satÄ±r")

    print(f"\nâœ… BirleÅŸtirilmiÅŸ test seti: {OUTPUT_TEST}")
    print(f"   Toplam: {len(combined_test)} satÄ±r")

    print("\nğŸ’¡ Åimdi preprocessing_word2vec.py'yi Ã§alÄ±ÅŸtÄ±rÄ±n!")
    print("   (combined_train.csv ve combined_test.csv kullanÄ±lacak)")


if __name__ == "__main__":
    merge_datasets()